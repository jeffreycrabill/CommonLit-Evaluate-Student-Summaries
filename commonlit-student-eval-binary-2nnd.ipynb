{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Libraries for data manipulation and linear algebra\nimport numpy as np \nimport pandas as pd \n\n# For file paths\nfrom pathlib import Path  \n\n# Tensorflow and Keras for Neural Network\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.regularizers import l2\n\n# Scikit-learn libraries for preprocessing, model evaluation, and text vectorization\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics import mean_squared_error\n\n# Libraries for text processing\nimport re\nimport spacy\nfrom spacy.lang.en import English \nfrom spacy.lang.en.stop_words import STOP_WORDS\n\n# Visualization\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# Display input files\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-05T20:52:30.679064Z","iopub.execute_input":"2023-09-05T20:52:30.679437Z","iopub.status.idle":"2023-09-05T20:52:47.98134Z","shell.execute_reply.started":"2023-09-05T20:52:30.679406Z","shell.execute_reply":"2023-09-05T20:52:47.98003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load and Preprocess Dataset","metadata":{}},{"cell_type":"code","source":"# Load the dataset\nfile_path = '/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv'\nse = pd.read_csv(file_path)\n\n# Drop rows with missing 'wording' and 'content'\nse.dropna(subset=['wording', 'content'], inplace=True)\n\n# Fill missing 'text' values\nse['text'].fillna('', inplace=True)\n\n# Text preprocessing function\ndef preprocess_text(text):\n    text = text.replace('\\n', ' ').lower()\n    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n    text = ' '.join([word for word in text.split() if word.isalpha() and word not in STOP_WORDS])\n    return ' '.join(text.split())\n\n# Apply the preprocessing function to texts\nse['PreprocessedText'] = se['text'].apply(preprocess_text)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vectorization of Text Data","metadata":{}},{"cell_type":"code","source":"# Vectorize preprocessed texts\nvectorizer = CountVectorizer(binary=True, max_features=5000)\nX = vectorizer.fit_transform(se['PreprocessedText'])\n\n# Split data for 'wording' and 'content' models\ny_wording = se['wording'].values\ny_content = se['content'].values\n\nX_train_wording, X_test_wording, y_train_wording, y_test_wording = train_test_split(X, y_wording, test_size=0.2, random_state=42)\nX_train_content, X_test_content, y_train_content, y_test_content = train_test_split(X, y_content, test_size=0.2, random_state=42)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T20:52:48.668999Z","iopub.execute_input":"2023-09-05T20:52:48.669518Z","iopub.status.idle":"2023-09-05T20:52:49.09389Z","shell.execute_reply.started":"2023-09-05T20:52:48.669435Z","shell.execute_reply":"2023-09-05T20:52:49.092556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Preparation for Neural Network","metadata":{}},{"cell_type":"code","source":"# Convert sparse matrix to dense format\nX_train_wording_dense = X_train_wording.toarray()\nX_test_wording_dense = X_test_wording.toarray()\n\nX_train_content_dense = X_train_content.toarray()\nX_test_content_dense = X_test_content.toarray()\n\n\n# Scale data\nscaler = StandardScaler()\nX_train_wording_scaled = scaler.fit_transform(X_train_wording_dense)\nX_test_wording_scaled = scaler.transform(X_test_wording_dense)\n\nX_train_content_scaled = scaler.fit_transform(X_train_content_dense)\nX_test_content_scaled = scaler.transform(X_test_content_dense)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T20:52:49.095378Z","iopub.execute_input":"2023-09-05T20:52:49.095751Z","iopub.status.idle":"2023-09-05T20:52:49.949226Z","shell.execute_reply.started":"2023-09-05T20:52:49.095705Z","shell.execute_reply":"2023-09-05T20:52:49.947883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Neural Network Model Building and Training","metadata":{}},{"cell_type":"code","source":"# Define model architecture for wording\nhidden_nodes_l1 = (X_train_wording_scaled.shape[1] + 1) // 2\nhidden_nodes_l2 = (hidden_nodes_l1 + 1) // 2\nhidden_nodes_l3 = (hidden_nodes_l2 + 1) // 2\nhidden_nodes_l4 = (hidden_nodes_l3 + 1) // 2\n\nmodel_wording = Sequential([\n    Dense(hidden_nodes_l1, input_dim=X_train_wording_scaled.shape[1], activation='relu', kernel_regularizer=l2(0.001)),\n    Dropout(0.25),\n    Dense(hidden_nodes_l2, activation='tanh', kernel_regularizer=l2(0.001)),\n    Dropout(0.25),\n    Dense(hidden_nodes_l3, activation='relu', kernel_regularizer=l2(0.001)),\n    Dropout(0.25),\n    Dense(hidden_nodes_l4, activation='tanh', kernel_regularizer=l2(0.001)),\n    Dense(1, activation='sigmoid')  \n])\n\n#model_wording = create_model(X_train_wording_dense.shape[1])\nmodel_wording.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\nmodel_wording.fit(X_train_wording_scaled, y_train_wording, epochs=50, batch_size=32, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T20:52:49.95181Z","iopub.execute_input":"2023-09-05T20:52:49.952734Z","iopub.status.idle":"2023-09-05T20:53:16.558737Z","shell.execute_reply.started":"2023-09-05T20:52:49.952668Z","shell.execute_reply":"2023-09-05T20:53:16.556686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define model architecture for content\nhidden_nodes_l1 = (X_train_content_scaled.shape[1] + 1) // 2\nhidden_nodes_l2 = (hidden_nodes_l1 + 1) // 2\nhidden_nodes_l3 = (hidden_nodes_l2 + 1) // 2\nhidden_nodes_l4 = (hidden_nodes_l3 + 1) // 2\n\nmodel_content = Sequential([\n    Dense(hidden_nodes_l1, input_dim=X_train_content_scaled.shape[1], activation='relu', kernel_regularizer=l2(0.001)),\n    Dropout(0.25),\n    Dense(hidden_nodes_l2, activation='tanh', kernel_regularizer=l2(0.001)),\n    Dropout(0.25),\n    Dense(hidden_nodes_l3, activation='relu', kernel_regularizer=l2(0.001)),\n    Dropout(0.25),\n    Dense(hidden_nodes_l4, activation='tanh', kernel_regularizer=l2(0.001)),\n    Dense(1, activation='sigmoid')  \n])\n\n#model_content = create_model(X_train_content_dense.shape[1])\nmodel_content.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\nmodel_content.fit(X_train_content_scaled, y_train_content, epochs=50, batch_size=32, validation_split=0.2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluation","metadata":{}},{"cell_type":"code","source":"# Predict on test data\ny_pred_wording = model_wording.predict(X_test_wording_scaled)\nrmse_wording = mean_squared_error(y_test_wording, y_pred_wording, squared=False)\nprint(f\"RMSE for wording: {rmse_wording}\")\n\ny_pred_content = model_content.predict(X_test_content_scaled)\nrmse_content = mean_squared_error(y_test_content, y_pred_content, squared=False)\nprint(f\"RMSE for content: {rmse_content}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-19T15:02:29.016401Z","iopub.execute_input":"2023-09-19T15:02:29.017587Z","iopub.status.idle":"2023-09-19T15:02:29.446003Z","shell.execute_reply.started":"2023-09-19T15:02:29.017540Z","shell.execute_reply":"2023-09-19T15:02:29.444761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare Submission for Competition","metadata":{}},{"cell_type":"code","source":"# Load test dataset for competition\ntest_df = pd.read_csv(Path(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\"))\n\n# Preprocess and vectorize the test data\ntest_df['PreprocessedText'] = test_df['text'].apply(preprocess_text)\nX_test_competition = vectorizer.transform(test_df['PreprocessedText'])\n\n# Predict using the trained models\npredictions_wording = model_wording.predict(X_test_competition)\npredictions_content = model_content.predict(X_test_competition)\n\n# Prepare submission DataFrame\nsubmission_df = pd.DataFrame({\n    'student_id': test_df['student_id'],\n    'content': predictions_content.squeeze(),\n    'wording': predictions_wording.squeeze()\n})\n\n\n# Clip values to be within expected bounds\nsubmission_df['content'] = np.clip(submission_df['content'], -2, 5)\nsubmission_df['wording'] = np.clip(submission_df['wording'], -2, 5)\n\n# Save submission to a CSV\nsubmission_df.to_csv(\"submission.csv\", index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T20:53:16.562172Z","iopub.status.idle":"2023-09-05T20:53:16.562583Z","shell.execute_reply.started":"2023-09-05T20:53:16.562395Z","shell.execute_reply":"2023-09-05T20:53:16.562414Z"},"trusted":true},"execution_count":null,"outputs":[]}]}